{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des bibliothèques nécessaires et initialiser du dataframee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier contenant les vidéos\n",
    "video_folder = \"../data/videos/\"\n",
    "output_video_folder = \"../data/videos_compressed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression de BETHOUX_camille.mp4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos/BETHOUX_camille.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42isom\n",
      "  Duration: 00:00:37.76, start: 0.000000, bitrate: 1504 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Baseline) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 848x480, 1439 kb/s, 29.95 fps, 30 tbr, 600 tbn (default)\n",
      "      Metadata:\n",
      "        vendor_id       : [0][0][0][0]\n",
      "      Side data:\n",
      "        displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 62 kb/s (default)\n",
      "      Metadata:\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x13d907e10] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x13d907e10] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 0x13d907e10] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=2 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=6 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=30 rc=crf mbtree=1 crf=28.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '../data/videos_compressed/BETHOUX_camille.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp42isom\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 480x848, q=2-31, 30 fps, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 aac\n",
      "[out#0/mp4 @ 0x13cf0f610] video:2124KiB audio:597KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.509998%\n",
      "frame= 1130 fps=321 q=-1.0 Lsize=    2763KiB time=00:00:37.66 bitrate= 600.8kbits/s speed=10.7x    \n",
      "[libx264 @ 0x13d907e10] frame I:5     Avg QP:25.43  size:  9656\n",
      "[libx264 @ 0x13d907e10] frame P:327   Avg QP:27.58  size:  3777\n",
      "[libx264 @ 0x13d907e10] frame B:798   Avg QP:29.49  size:  1117\n",
      "[libx264 @ 0x13d907e10] consecutive B-frames:  4.2%  2.8%  5.8% 87.1%\n",
      "[libx264 @ 0x13d907e10] mb I  I16..4: 35.7% 55.4%  8.9%\n",
      "[libx264 @ 0x13d907e10] mb P  I16..4:  8.0%  8.4%  0.6%  P16..4: 38.9%  7.7%  2.5%  0.0%  0.0%    skip:33.9%\n",
      "[libx264 @ 0x13d907e10] mb B  I16..4:  1.7%  2.0%  0.0%  B16..8: 20.7%  2.7%  0.1%  direct: 3.7%  skip:69.0%  L0:43.7% L1:51.4% BI: 4.9%\n",
      "[libx264 @ 0x13d907e10] 8x8 transform intra:51.3% inter:79.0%\n",
      "[libx264 @ 0x13d907e10] coded y,uvDC,uvAC intra: 23.6% 34.1% 4.6% inter: 4.6% 5.1% 0.0%\n",
      "[libx264 @ 0x13d907e10] i16 v,h,dc,p: 30% 19% 16% 35%\n",
      "[libx264 @ 0x13d907e10] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 23% 14% 32%  5%  5%  5%  5%  7%  4%\n",
      "[libx264 @ 0x13d907e10] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 28% 13% 21%  6%  7%  8%  6%  7%  3%\n",
      "[libx264 @ 0x13d907e10] i8c dc,h,v,p: 65% 14% 18%  3%\n",
      "[libx264 @ 0x13d907e10] Weighted P-Frames: Y:1.2% UV:0.0%\n",
      "[libx264 @ 0x13d907e10] ref P L0: 68.8% 31.2%\n",
      "[libx264 @ 0x13d907e10] ref B L0: 85.7% 14.3%\n",
      "[libx264 @ 0x13d907e10] ref B L1: 96.5%  3.5%\n",
      "[libx264 @ 0x13d907e10] kb/s:461.04\n",
      "[aac @ 0x13d92d3e0] Qavg: 823.373\n",
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos/MICHEL_Bernard.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 6.182387\n",
      "    com.apple.quicktime.location.ISO6709: +33.9892-006.8193+087.123/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone SE (3rd generation)\n",
      "    com.apple.quicktime.software: 17.6.1\n",
      "    com.apple.quicktime.creationdate: 2024-10-24T22:15:07+0100\n",
      "  Duration: 00:00:33.93, start: 0.000000, bitrate: 15587 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, 15334 kb/s, 29.97 fps, 29.97 tbr, 600 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : H.264\n",
      "      Side data:\n",
      "        displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 166 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 23 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 49 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x15390a9e0] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x15390a9e0] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x15390a9e0] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=2 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=6 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=30 rc=crf mbtree=1 crf=28.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mov, to '../data/videos_compressed/MICHEL_Bernard.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-10-24T22:15:07+0100\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 6.182387\n",
      "    com.apple.quicktime.location.ISO6709: +33.9892-006.8193+087.123/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone SE (3rd generation)\n",
      "    com.apple.quicktime.software: 17.6.1\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920, q=2-31, 29.97 fps, 30k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T21:15:07.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 aac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression de MICHEL_Bernard.MOV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mov @ 0x15390a6f0] video:4845KiB audio:547KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.694439%\n",
      "frame= 1017 fps= 70 q=-1.0 Lsize=    5429KiB time=00:00:33.86 bitrate=1313.2kbits/s speed=2.33x    \n",
      "[libx264 @ 0x15390a9e0] frame I:6     Avg QP:26.05  size: 41712\n",
      "[libx264 @ 0x15390a9e0] frame P:258   Avg QP:27.28  size:  8883\n",
      "[libx264 @ 0x15390a9e0] frame B:753   Avg QP:28.42  size:  3211\n",
      "[libx264 @ 0x15390a9e0] consecutive B-frames:  0.8%  1.2%  0.9% 97.1%\n",
      "[libx264 @ 0x15390a9e0] mb I  I16..4: 32.5% 60.7%  6.8%\n",
      "[libx264 @ 0x15390a9e0] mb P  I16..4:  5.0%  4.9%  0.1%  P16..4: 25.9%  2.8%  1.6%  0.0%  0.0%    skip:59.7%\n",
      "[libx264 @ 0x15390a9e0] mb B  I16..4:  1.7%  1.8%  0.0%  B16..8:  8.8%  0.7%  0.0%  direct: 5.4%  skip:81.6%  L0:43.3% L1:55.1% BI: 1.6%\n",
      "[libx264 @ 0x15390a9e0] 8x8 transform intra:51.0% inter:89.4%\n",
      "[libx264 @ 0x15390a9e0] coded y,uvDC,uvAC intra: 15.6% 39.4% 2.5% inter: 2.7% 6.5% 0.0%\n",
      "[libx264 @ 0x15390a9e0] i16 v,h,dc,p: 40% 25% 16% 20%\n",
      "[libx264 @ 0x15390a9e0] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 12% 57%  3%  4%  3%  3%  3%  2%\n",
      "[libx264 @ 0x15390a9e0] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 19% 19%  6%  7%  7%  6%  5%  4%\n",
      "[libx264 @ 0x15390a9e0] i8c dc,h,v,p: 60% 18% 20%  2%\n",
      "[libx264 @ 0x15390a9e0] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x15390a9e0] ref P L0: 57.7% 42.3%\n",
      "[libx264 @ 0x15390a9e0] ref B L0: 75.1% 24.9%\n",
      "[libx264 @ 0x15390a9e0] ref B L1: 93.6%  6.4%\n",
      "[libx264 @ 0x15390a9e0] kb/s:1169.39\n",
      "[aac @ 0x152f28c00] Qavg: 708.172\n",
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos/BARTOZZI_Mathieu.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 45.039206\n",
      "    com.apple.quicktime.location.ISO6709: +33.9892-006.8197+090.432/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone SE (3rd generation)\n",
      "    com.apple.quicktime.software: 17.6.1\n",
      "    com.apple.quicktime.creationdate: 2024-10-24T21:54:50+0100\n",
      "  Duration: 00:00:51.15, start: 0.000000, bitrate: 15621 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, 15365 kb/s, 29.97 fps, 29.97 tbr, 600 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : H.264\n",
      "      Side data:\n",
      "        displaymatrix: rotation of -90.00 degrees\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 168 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:2[0x3](und): Data: none (mebx / 0x7862656D), 0 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "  Stream #0:3[0x4](und): Data: none (mebx / 0x7862656D), 23 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "  Stream #0:4[0x5](und): Data: none (mebx / 0x7862656D), 49 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Metadata\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0x12d826b50] using cpu capabilities: ARMv8 NEON\n",
      "[libx264 @ 0x12d826b50] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0x12d826b50] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=2 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=6 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=1 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=30 rc=crf mbtree=1 crf=28.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mov, to '../data/videos_compressed/BARTOZZI_Mathieu.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 0\n",
      "    compatible_brands: qt  \n",
      "    com.apple.quicktime.creationdate: 2024-10-24T21:54:50+0100\n",
      "    com.apple.quicktime.location.accuracy.horizontal: 45.039206\n",
      "    com.apple.quicktime.location.ISO6709: +33.9892-006.8197+090.432/\n",
      "    com.apple.quicktime.make: Apple\n",
      "    com.apple.quicktime.model: iPhone SE (3rd generation)\n",
      "    com.apple.quicktime.software: 17.6.1\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920, q=2-31, 29.97 fps, 30k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-10-24T20:54:50.000000Z\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 aac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression de BARTOZZI_Mathieu.MOV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame= 1469 fps= 62 q=34.0 size=   11520KiB time=00:00:48.94 bitrate=1928.0kbits/s speed=2.07x     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression terminée.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mov @ 0x12d825df0] video:11320KiB audio:819KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.458730%\n",
      "frame= 1533 fps= 63 q=-1.0 Lsize=   12194KiB time=00:00:51.08 bitrate=1955.5kbits/s speed=2.11x    \n",
      "[libx264 @ 0x12d826b50] frame I:10    Avg QP:26.20  size: 37567\n",
      "[libx264 @ 0x12d826b50] frame P:387   Avg QP:27.81  size: 12649\n",
      "[libx264 @ 0x12d826b50] frame B:1136  Avg QP:29.13  size:  5563\n",
      "[libx264 @ 0x12d826b50] consecutive B-frames:  1.0%  0.4%  0.8% 97.8%\n",
      "[libx264 @ 0x12d826b50] mb I  I16..4: 33.9% 60.6%  5.6%\n",
      "[libx264 @ 0x12d826b50] mb P  I16..4:  8.4%  9.4%  0.2%  P16..4: 30.6%  3.7%  1.8%  0.0%  0.0%    skip:45.9%\n",
      "[libx264 @ 0x12d826b50] mb B  I16..4:  3.0%  4.2%  0.0%  B16..8: 13.3%  1.3%  0.0%  direct: 8.5%  skip:69.7%  L0:45.4% L1:52.7% BI: 1.9%\n",
      "[libx264 @ 0x12d826b50] 8x8 transform intra:55.9% inter:88.9%\n",
      "[libx264 @ 0x12d826b50] coded y,uvDC,uvAC intra: 18.0% 40.8% 2.4% inter: 4.2% 10.0% 0.0%\n",
      "[libx264 @ 0x12d826b50] i16 v,h,dc,p: 33% 26% 15% 26%\n",
      "[libx264 @ 0x12d826b50] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 13% 49%  3%  5%  4%  4%  4%  3%\n",
      "[libx264 @ 0x12d826b50] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 18% 20%  6%  7%  7%  6%  5%  3%\n",
      "[libx264 @ 0x12d826b50] i8c dc,h,v,p: 62% 18% 17%  2%\n",
      "[libx264 @ 0x12d826b50] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x12d826b50] ref P L0: 58.6% 41.4%\n",
      "[libx264 @ 0x12d826b50] ref B L0: 78.3% 21.7%\n",
      "[libx264 @ 0x12d826b50] ref B L1: 94.0%  6.0%\n",
      "[libx264 @ 0x12d826b50] kb/s:1812.76\n",
      "[aac @ 0x12ce5fe80] Qavg: 626.299\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Chemin vers le dossier contenant les vidéos\n",
    "video_folder = \"../data/videos/\"\n",
    "output_video_folder = \"../data/videos_compressed/\"\n",
    "\n",
    "# # Créer le dossier de sortie si nécessaire\n",
    "# if not os.path.exists(output_video_folder):\n",
    "#     os.makedirs(output_video_folder)\n",
    "\n",
    "# Fonction pour compresser une vidéo avec FFmpeg\n",
    "def compress_video(input_path, output_path):\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-i\", input_path,\n",
    "        \"-vcodec\", \"libx264\",\n",
    "        \"-crf\", \"28\",  # Ajuste la qualité ici si nécessaire\n",
    "        \"-preset\", \"fast\",\n",
    "        \"-acodec\", \"aac\", \"-strict\", \"-2\",\n",
    "        output_path\n",
    "    ]\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Parcourir toutes les vidéos dans le dossier\n",
    "for video_file in os.listdir(video_folder):\n",
    "    if video_file.endswith(('.mp4', '.avi', '.mov', '.mkv','MOV')):  # Filtrer les formats vidéo\n",
    "        input_video_path = os.path.join(video_folder, video_file)\n",
    "        output_video_path = os.path.join(output_video_folder, video_file)\n",
    "\n",
    "        print(f\"Compression de {video_file}...\")\n",
    "        compress_video(input_video_path, output_video_path)\n",
    "\n",
    "print(\"Compression terminée.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour extraire les noms et prénoms à partir des fichiers vidéos\n",
    "\n",
    "def extract_names_from_videos(video_folder):\n",
    "    video_files = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov', 'MOV'))]\n",
    "\n",
    "    # Séparer le nom et le prénom en supposant que le format est \"NOM_prénom.xxx\"\n",
    "    data = []\n",
    "    for video in video_files:\n",
    "        base_name = os.path.splitext(video)[0]  # Enlever l'extension (.mp4, .avi, etc.)\n",
    "        if '_' in base_name:\n",
    "            nom, prenom = base_name.split('_', 1)  # Séparer sur le premier '_'\n",
    "        else:\n",
    "            nom, prenom = base_name, ''  # Si pas de '_', mettre prénom vide\n",
    "\n",
    "        data.append({'video_file': video, 'nom': nom, 'prénom': prenom})\n",
    "\n",
    "    # Créer un DataFrame\n",
    "    df_videos = pd.DataFrame(data)\n",
    "    return df_videos\n",
    "\n",
    "df_videos=extract_names_from_videos(output_video_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction du transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Spécifie le modèle Whisper à utiliser\n",
    "whisper_model_name = \"base\"  # Par exemple, \"tiny\", \"base\", \"small\", \"medium\", ou \"large\"\n",
    "whisper_model = whisper.load_model(whisper_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour transcrire une vidéo avec Whisper\n",
    "def transcribe_video(whisper_model, video_path):\n",
    "    result = whisper_model.transcribe(video_path)\n",
    "    return result['text']\n",
    "\n",
    "# Ajouter une colonne 'transcript' avec les transcriptions de chaque vidéo\n",
    "df_videos['transcript'] = df_videos['video_file'].apply(\n",
    "    lambda video_file: transcribe_video(whisper_model, os.path.join(output_video_folder, video_file))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_file</th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX_camille.mp4</td>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>Bonjour, je vais répondre à l'offre de Simnac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL_Bernard.MOV</td>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>Bonjour, je suis Ravi de postuler pour le pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI_Mathieu.MOV</td>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>Bonjour, je suis rapide de répondre à l'offre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_file       nom   prénom  \\\n",
       "0   BETHOUX_camille.mp4   BETHOUX  camille   \n",
       "1    MICHEL_Bernard.MOV    MICHEL  Bernard   \n",
       "2  BARTOZZI_Mathieu.MOV  BARTOZZI  Mathieu   \n",
       "\n",
       "                                          transcript  \n",
       "0   Bonjour, je vais répondre à l'offre de Simnac...  \n",
       "1   Bonjour, je suis Ravi de postuler pour le pos...  \n",
       "2   Bonjour, je suis rapide de répondre à l'offre...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse non-verbale avec Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729847355.229877 3671445 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1729847355.427130 3674578 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1729847355.445899 3674576 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialiser Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "# Initialiser Mediapipe Drawing pour dessiner les repères sur l'image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Landmarks clés à surveiller (poignets, coudes, épaules)\n",
    "key_landmarks = {\n",
    "    'left_wrist': 15,\n",
    "    'right_wrist': 16,\n",
    "    'left_elbow': 13,\n",
    "    'right_elbow': 14,\n",
    "    'left_shoulder': 11,\n",
    "    'right_shoulder': 12\n",
    "}\n",
    "\n",
    "# Fonction pour analyser une vidéo et extraire les key landmarks\n",
    "def analyze_video_key_landmarks(video_path):\n",
    "    \"\"\"Analyse la vidéo et extrait uniquement les key landmarks.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    pose_data = []  # Stocker les résultats des key landmarks\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # Fin de la vidéo\n",
    "\n",
    "        # Convertir l'image en format RGB pour Mediapipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Obtenir les résultats de pose (simuler la fonction process de Mediapipe)\n",
    "        results = pose.process(rgb_frame)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Extraire les key landmarks\n",
    "            key_landmarks_data = {\n",
    "                name: (landmarks[idx].x, landmarks[idx].y, landmarks[idx].visibility)\n",
    "                for name, idx in key_landmarks.items()\n",
    "            }\n",
    "            pose_data.append(key_landmarks_data)\n",
    "\n",
    "    cap.release()\n",
    "    return pose_data  # Retourner uniquement les key landmarks\n",
    "\n",
    "# Ajouter les données de posture dans le DataFrame pour chaque vidéo\n",
    "df_videos['pose_data'] = df_videos['video_file'].apply(\n",
    "    lambda video_file: analyze_video_key_landmarks(os.path.join(output_video_folder, video_file))\n",
    ")\n",
    "\n",
    "# Fonction pour calculer les mouvements et la visibilité moyenne\n",
    "def calculate_movement_and_visibility(pose_data):\n",
    "    \"\"\"Calcule les mouvements et la visibilité moyenne des key landmarks sur plusieurs frames.\"\"\"\n",
    "    total_movement = {landmark: 0 for landmark in key_landmarks}\n",
    "    visibility_stats = {landmark: [] for landmark in key_landmarks}\n",
    "\n",
    "    for prev_frame, curr_frame in zip(pose_data[:-1], pose_data[1:]):\n",
    "        for landmark_name in key_landmarks:\n",
    "            prev_landmark = prev_frame[landmark_name]\n",
    "            curr_landmark = curr_frame[landmark_name]\n",
    "\n",
    "            if prev_landmark[2] > 0.5 and curr_landmark[2] > 0.5:  # Vérifie la visibilité\n",
    "                # Calcul de la distance euclidienne entre deux frames successives\n",
    "                dist = np.linalg.norm(np.array(curr_landmark[:2]) - np.array(prev_landmark[:2]))\n",
    "                total_movement[landmark_name] += dist\n",
    "\n",
    "            # Enregistrer la visibilité\n",
    "            visibility_stats[landmark_name].append(curr_landmark[2])\n",
    "\n",
    "    # Calcul des moyennes de visibilité\n",
    "    avg_visibility = {landmark: np.mean(vis) for landmark, vis in visibility_stats.items()}\n",
    "\n",
    "    return total_movement, avg_visibility\n",
    "\n",
    "# Appliquer la fonction pour chaque vidéo\n",
    "df_videos['movements'], df_videos['visibilities'] = zip(*df_videos['pose_data'].apply(\n",
    "    calculate_movement_and_visibility\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_file</th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>transcript</th>\n",
       "      <th>pose_data</th>\n",
       "      <th>movements</th>\n",
       "      <th>visibilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX_camille.mp4</td>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>Bonjour, je vais répondre à l'offre de Simnac...</td>\n",
       "      <td>[{'left_wrist': (1.0578941106796265, 1.1902699...</td>\n",
       "      <td>{'left_wrist': 14.291328720337946, 'right_wris...</td>\n",
       "      <td>{'left_wrist': 0.7811209785333769, 'right_wris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL_Bernard.MOV</td>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>Bonjour, je suis Ravi de postuler pour le pos...</td>\n",
       "      <td>[{'left_wrist': (0.9465816617012024, 0.9347741...</td>\n",
       "      <td>{'left_wrist': 6.314228394392659, 'right_wrist...</td>\n",
       "      <td>{'left_wrist': 0.4683238630454371, 'right_wris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI_Mathieu.MOV</td>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>Bonjour, je suis rapide de répondre à l'offre...</td>\n",
       "      <td>[{'left_wrist': (0.43789562582969666, 0.971584...</td>\n",
       "      <td>{'left_wrist': 26.5384105406569, 'right_wrist'...</td>\n",
       "      <td>{'left_wrist': 0.8951871749548626, 'right_wris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_file       nom   prénom  \\\n",
       "0   BETHOUX_camille.mp4   BETHOUX  camille   \n",
       "1    MICHEL_Bernard.MOV    MICHEL  Bernard   \n",
       "2  BARTOZZI_Mathieu.MOV  BARTOZZI  Mathieu   \n",
       "\n",
       "                                          transcript  \\\n",
       "0   Bonjour, je vais répondre à l'offre de Simnac...   \n",
       "1   Bonjour, je suis Ravi de postuler pour le pos...   \n",
       "2   Bonjour, je suis rapide de répondre à l'offre...   \n",
       "\n",
       "                                           pose_data  \\\n",
       "0  [{'left_wrist': (1.0578941106796265, 1.1902699...   \n",
       "1  [{'left_wrist': (0.9465816617012024, 0.9347741...   \n",
       "2  [{'left_wrist': (0.43789562582969666, 0.971584...   \n",
       "\n",
       "                                           movements  \\\n",
       "0  {'left_wrist': 14.291328720337946, 'right_wris...   \n",
       "1  {'left_wrist': 6.314228394392659, 'right_wrist...   \n",
       "2  {'left_wrist': 26.5384105406569, 'right_wrist'...   \n",
       "\n",
       "                                        visibilities  \n",
       "0  {'left_wrist': 0.7811209785333769, 'right_wris...  \n",
       "1  {'left_wrist': 0.4683238630454371, 'right_wris...  \n",
       "2  {'left_wrist': 0.8951871749548626, 'right_wris...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesurer le débit de parole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Fonction pour calculer la durée d'une vidéo en minutes\n",
    "def get_video_duration(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return 0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # Taux de frames par seconde\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Nombre total de frames\n",
    "    duration_seconds = frame_count / fps  # Durée en secondes\n",
    "    cap.release()\n",
    "    return duration_seconds / 60  # Convertir en minutes\n",
    "\n",
    "# Fonction pour compter les mots dans une transcription\n",
    "def count_words(transcript):\n",
    "    return len(transcript.split())\n",
    "\n",
    "# Calculer le débit de parole (mots par minute)\n",
    "def calculate_speech_rate(transcript, video_duration_minutes):\n",
    "    word_count = count_words(transcript)\n",
    "    if video_duration_minutes > 0:\n",
    "        return word_count / video_duration_minutes  # Mots par minute\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Ajouter une colonne 'speech_rate' avec le débit de parole\n",
    "df_videos['speech_rate'] = df_videos.apply(\n",
    "    lambda row: calculate_speech_rate(row['transcript'], get_video_duration(os.path.join(video_folder, row['video_file']))),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_file</th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>transcript</th>\n",
       "      <th>pose_data</th>\n",
       "      <th>movements</th>\n",
       "      <th>visibilities</th>\n",
       "      <th>speech_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX_camille.mp4</td>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>Bonjour, je vais répondre à l'offre de Simnac...</td>\n",
       "      <td>[{'left_wrist': (1.0578941106796265, 1.1902699...</td>\n",
       "      <td>{'left_wrist': 14.291328720337946, 'right_wris...</td>\n",
       "      <td>{'left_wrist': 0.7811209785333769, 'right_wris...</td>\n",
       "      <td>130.388693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL_Bernard.MOV</td>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>Bonjour, je suis Ravi de postuler pour le pos...</td>\n",
       "      <td>[{'left_wrist': (0.9465816617012024, 0.9347741...</td>\n",
       "      <td>{'left_wrist': 6.314228394392659, 'right_wrist...</td>\n",
       "      <td>{'left_wrist': 0.4683238630454371, 'right_wris...</td>\n",
       "      <td>141.446884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI_Mathieu.MOV</td>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>Bonjour, je suis rapide de répondre à l'offre...</td>\n",
       "      <td>[{'left_wrist': (0.43789562582969666, 0.971584...</td>\n",
       "      <td>{'left_wrist': 26.5384105406569, 'right_wrist'...</td>\n",
       "      <td>{'left_wrist': 0.8951871749548626, 'right_wris...</td>\n",
       "      <td>159.520396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             video_file       nom   prénom  \\\n",
       "0   BETHOUX_camille.mp4   BETHOUX  camille   \n",
       "1    MICHEL_Bernard.MOV    MICHEL  Bernard   \n",
       "2  BARTOZZI_Mathieu.MOV  BARTOZZI  Mathieu   \n",
       "\n",
       "                                          transcript  \\\n",
       "0   Bonjour, je vais répondre à l'offre de Simnac...   \n",
       "1   Bonjour, je suis Ravi de postuler pour le pos...   \n",
       "2   Bonjour, je suis rapide de répondre à l'offre...   \n",
       "\n",
       "                                           pose_data  \\\n",
       "0  [{'left_wrist': (1.0578941106796265, 1.1902699...   \n",
       "1  [{'left_wrist': (0.9465816617012024, 0.9347741...   \n",
       "2  [{'left_wrist': (0.43789562582969666, 0.971584...   \n",
       "\n",
       "                                           movements  \\\n",
       "0  {'left_wrist': 14.291328720337946, 'right_wris...   \n",
       "1  {'left_wrist': 6.314228394392659, 'right_wrist...   \n",
       "2  {'left_wrist': 26.5384105406569, 'right_wrist'...   \n",
       "\n",
       "                                        visibilities  speech_rate  \n",
       "0  {'left_wrist': 0.7811209785333769, 'right_wris...   130.388693  \n",
       "1  {'left_wrist': 0.4683238630454371, 'right_wris...   141.446884  \n",
       "2  {'left_wrist': 0.8951871749548626, 'right_wris...   159.520396  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_videos.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure du ton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "audio_folder = \"../data/audios\"\n",
    "\n",
    "\n",
    "# Fonction pour extraire l'audio d'une vidéo et l'enregistrer dans le dossier audios\n",
    "def extract_audio(video_path, output_audio_path):\n",
    "    command = f\"ffmpeg -i {video_path} -q:a 0 -map a {output_audio_path} -y\"\n",
    "    subprocess.call(command, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pitch_variation(audio_path):\n",
    "    # Charger l'audio avec Librosa\n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    # Ajuster la taille de la fenêtre et le hop_length\n",
    "    frame_length = 1024  # Taille de la fenêtre d'analyse (réduite pour s'adapter)\n",
    "    hop_length = 256      # Intervalle entre deux analyses de pitch (réduit pour plus de finesse)\n",
    "\n",
    "    # Utiliser pyin pour extraire la fréquence fondamentale (pitch)\n",
    "    pitches, voiced_flag, voiced_probs = librosa.pyin(\n",
    "        y, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), sr=sr, frame_length=frame_length, hop_length=hop_length\n",
    "    )\n",
    "\n",
    "    # Ne garder que les pitchs valides (voiced_flag = True)\n",
    "    valid_pitches = pitches[~np.isnan(pitches)]\n",
    "\n",
    "    if len(valid_pitches) == 0:\n",
    "        return 0, 0  # Retourne 0 si aucun pitch n'est détecté\n",
    "\n",
    "    # Calculer l'écart-type du pitch sur toute la vidéo\n",
    "    pitch_mean = np.mean(valid_pitches)\n",
    "    pitch_std = np.std(valid_pitches)\n",
    "\n",
    "    return pitch_mean, pitch_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos_compressed/BETHOUX_camille.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:00:37.76, start: 0.000000, bitrate: 599 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 480x848, 461 kb/s, 29.95 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 129 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to '../data/audios/BETHOUX_camille.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 pcm_s16le\n",
      "[out#0/wav @ 0x12781fc00] video:0KiB audio:6504KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.001171%\n",
      "size=    6504KiB time=00:00:37.75 bitrate=1411.2kbits/s speed=1.29e+03x    \n",
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos_compressed/MICHEL_Bernard.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 512\n",
      "    compatible_brands: qt  \n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:00:33.95, start: 0.000000, bitrate: 1310 kb/s\n",
      "  Stream #0:0[0x1]: Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920, 1169 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : FFMP\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2]: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mov, to '../data/audios/MICHEL_Bernard.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 512\n",
      "    compatible_brands: qt  \n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 aac\n",
      "[out#0/mov @ 0x135f06350] video:0KiB audio:572KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.144446%\n",
      "size=     579KiB time=00:00:33.94 bitrate= 139.6kbits/s speed=73.8x    \n",
      "[aac @ 0x135f06ef0] Qavg: 120.000\n",
      "ffmpeg version 7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.100 / 61. 19.100\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../data/videos_compressed/BARTOZZI_Mathieu.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 512\n",
      "    compatible_brands: qt  \n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:00:51.15, start: 0.000000, bitrate: 1952 kb/s\n",
      "  Stream #0:0[0x1]: Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1080x1920, 1812 kb/s, 29.97 fps, 29.97 tbr, 30k tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Video\n",
      "        vendor_id       : FFMP\n",
      "        encoder         : Lavc61.19.100 libx264\n",
      "  Stream #0:1[0x2]: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 131 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mov, to '../data/audios/BARTOZZI_Mathieu.MOV':\n",
      "  Metadata:\n",
      "    major_brand     : qt  \n",
      "    minor_version   : 512\n",
      "    compatible_brands: qt  \n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : Core Media Audio\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.100 aac\n",
      "[out#0/mov @ 0x12b619f30] video:0KiB audio:864KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 1.092844%\n",
      "size=     873KiB time=00:00:51.15 bitrate= 139.9kbits/s speed=  75x    \n",
      "[aac @ 0x12b611ae0] Qavg: 120.000\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/3601006044.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(audio_path)\n",
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ajouter une nouvelle colonne 'audio_file' en modifiant uniquement cette colonne\n",
    "df_videos['audio_file'] = df_videos['video_file'].apply(\n",
    "    lambda video_file: video_file.replace('.mp4', '.wav')  # Exemple : remplacer l'extension .mp4 par .wav\n",
    ")\n",
    "\n",
    "# Extraire l'audio pour chaque vidéo et l'enregistrer dans le dossier audios\n",
    "for video_file, audio_file in zip(df_videos['video_file'], df_videos['audio_file']):\n",
    "    extract_audio(os.path.join(output_video_folder, video_file), os.path.join(audio_folder, audio_file))\n",
    "\n",
    "\n",
    "# Analyser les variations de pitch après l'extraction audio\n",
    "df_videos['pitch_mean'], df_videos['pitch_std'] = zip(*df_videos['audio_file'].apply(\n",
    "    lambda audio_file: analyze_pitch_variation(os.path.join(audio_folder, audio_file))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul des scores globaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score de communication non verbale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# utilisation de MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Création du  DataFrame df_score avec les colonnes 'nom' et 'prénom'\n",
    "df_score = df_videos[['nom', 'prénom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/597510668.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['movement_score'] = df_videos.apply(\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/597510668.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['movement_score'] = scaler.fit_transform(df_score[['movement_score']])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Fonction pour calculer le score basé sur les mouvements et la visibilité\n",
    "def calculate_movement_rate(total_movement, avg_visibility):\n",
    "    # Pondérations des différents critères (ajustables selon tes besoins)\n",
    "    stability_weight = 0.3\n",
    "    gesture_weight = 0.5\n",
    "    diversity_weight = 0.2\n",
    "\n",
    "    # 1. Stabilité posturale : Basé sur la visibilité des épaules\n",
    "    stability_score = (avg_visibility['left_shoulder'] + avg_visibility['right_shoulder']) / 2\n",
    "\n",
    "    # 2. Dynamique gestuelle : Basé sur le mouvement des poignets et coudes\n",
    "    gesture_score = (total_movement['left_wrist'] + total_movement['right_wrist'] +\n",
    "                     total_movement['left_elbow'] + total_movement['right_elbow']) / 4\n",
    "\n",
    "    # 3. Diversité des gestes : Basé sur la différence entre les mouvements des deux côtés du corps\n",
    "    left_side_movement = total_movement['left_wrist'] + total_movement['left_elbow']\n",
    "    right_side_movement = total_movement['right_wrist'] + total_movement['right_elbow']\n",
    "\n",
    "    # Calcul de la diversité : si les deux côtés sont équilibrés en termes de mouvements\n",
    "    if max(left_side_movement, right_side_movement) > 0:\n",
    "        diversity_score = min(left_side_movement, right_side_movement) / max(left_side_movement, right_side_movement)\n",
    "    else:\n",
    "        diversity_score = 0\n",
    "\n",
    "    # Calcul du score lié au mouvement en pondérant les critères\n",
    "    movement_rate = (stability_score * stability_weight +\n",
    "                     gesture_score * gesture_weight +\n",
    "                     diversity_score * diversity_weight)\n",
    "\n",
    "    return movement_rate\n",
    "\n",
    "\n",
    "# Calculer les scores de movement_rate\n",
    "df_score['movement_score'] = df_videos.apply(\n",
    "    lambda row: calculate_movement_rate(row['movements'], row['visibilities']), axis=1\n",
    ")\n",
    "\n",
    "# Normalise le movement_rate\n",
    "df_score['movement_score'] = scaler.fit_transform(df_score[['movement_score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/1729928474.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['speech_score'] = calculate_speech_score(df_videos['speech_rate'])\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer le score de débit de parole (speech rate)\n",
    "def calculate_speech_score(speech_rate):\n",
    "    speech_rate_normalized = scaler.fit_transform(speech_rate.values.reshape(-1, 1))\n",
    "    return speech_rate_normalized\n",
    "\n",
    "# Appliquer la fonction pour calculer et normaliser le score de débit de parole (speech_rate)\n",
    "df_score['speech_score'] = calculate_speech_score(df_videos['speech_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/697916325.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['tone_score'] = calculate_tone_score(df_videos['pitch_mean'], df_videos['pitch_std'])\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour calculer le score du ton en combinant pitch_mean et pitch_std\n",
    "def calculate_tone_score(pitch_mean, pitch_std):\n",
    "\n",
    "    # Normaliser pitch_mean et pitch_std\n",
    "    pitch_mean_normalized = scaler.fit_transform(pitch_mean.values.reshape(-1, 1))\n",
    "    pitch_std_normalized = scaler.fit_transform(pitch_std.values.reshape(-1, 1))\n",
    "\n",
    "    # Calculer le score du ton avec des pondérations égales\n",
    "    tone_score = 0.5 * pitch_mean_normalized + 0.5 * pitch_std_normalized\n",
    "\n",
    "    return tone_score\n",
    "\n",
    "# Appliquer la fonction pour calculer et normaliser le score de ton (combinaison pitch_mean et pitch_std)\n",
    "df_score['tone_score'] = calculate_tone_score(df_videos['pitch_mean'], df_videos['pitch_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>movement_score</th>\n",
       "      <th>speech_score</th>\n",
       "      <th>tone_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>0.58554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.379593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nom   prénom  movement_score  speech_score  tone_score\n",
       "0   BETHOUX  camille         0.58554      0.000000    0.732170\n",
       "1    MICHEL  Bernard         0.00000      0.379593    0.000000\n",
       "2  BARTOZZI  Mathieu         1.00000      1.000000    0.625407"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et scoring du transcript NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Méthode STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Charger le modèle de langue français de spaCy\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Charger les mots-clés depuis le fichier JSON\n",
    "with open('../data/star_intro_keywords.json', 'r') as f:\n",
    "    star_intro_keywords = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/1019395148.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['intro_score'] = df_videos['transcript'].apply(\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/1019395148.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['star_score'] = df_videos['transcript'].apply(\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/1019395148.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score[['intro_score', 'star_score']] = scaler.fit_transform(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Scoring de l'introduction en utilisant spaCy pour la tokenisation et la segmentation\n",
    "def score_introduction(transcript, keywords):\n",
    "    doc = nlp(transcript)  # Tokenisation du transcript avec spaCy\n",
    "    return 1 if any(kw in sent.text.lower() for kw in keywords['justification'] for sent in doc.sents) else 0\n",
    "\n",
    "# Scoring de la méthode STAR en utilisant spaCy\n",
    "def score_star(transcript, keywords):\n",
    "    doc = nlp(transcript)  # Tokenisation du transcript avec spaCy\n",
    "    star_score = 0\n",
    "    # Vérification des différentes étapes de la méthode STAR\n",
    "    star_score += 1 if any(kw in sent.text.lower() for kw in keywords['situation'] for sent in doc.sents) else 0\n",
    "    star_score += 1 if any(kw in sent.text.lower() for kw in keywords['task'] for sent in doc.sents) else 0\n",
    "    star_score += 1 if any(kw in sent.text.lower() for kw in keywords['action'] for sent in doc.sents) else 0\n",
    "    star_score += 1 if any(kw in sent.text.lower() for kw in keywords['result'] for sent in doc.sents) else 0\n",
    "    return star_score\n",
    "\n",
    "\n",
    "# Appliquer la fonction de scoring pour l'introduction à chaque transcript\n",
    "df_score['intro_score'] = df_videos['transcript'].apply(\n",
    "    lambda transcript: score_introduction(transcript, star_intro_keywords)\n",
    ")\n",
    "\n",
    "# Appliquer la fonction de scoring pour la méthode STAR à chaque transcript\n",
    "df_score['star_score'] = df_videos['transcript'].apply(\n",
    "    lambda transcript: score_star(transcript, star_intro_keywords)\n",
    ")\n",
    "\n",
    "#Normalisation des scores\n",
    "df_score[['intro_score', 'star_score']] = scaler.fit_transform(\n",
    "        df_score[['intro_score', 'star_score']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>movement_score</th>\n",
       "      <th>speech_score</th>\n",
       "      <th>tone_score</th>\n",
       "      <th>intro_score</th>\n",
       "      <th>star_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>0.58554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.379593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nom   prénom  movement_score  speech_score  tone_score  intro_score  \\\n",
       "0   BETHOUX  camille         0.58554      0.000000    0.732170          0.0   \n",
       "1    MICHEL  Bernard         0.00000      0.379593    0.000000          0.0   \n",
       "2  BARTOZZI  Mathieu         1.00000      1.000000    0.625407          0.0   \n",
       "\n",
       "   star_score  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         0.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authenticité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire la liste des stopwords français depuis spaCy\n",
    "french_stopwords = list(nlp.Defaults.stop_words)  # Convertir en liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieubartozzi/.pyenv/versions/3.10.6/envs/video_auto_rating/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
      "  warnings.warn(\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_32873/584358175.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_score['authenticity_score'] = score_authenticity_tfidf(df_videos['transcript'].tolist(), french_stopwords)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fonction modifiée pour calculer les scores TF-IDF\n",
    "def score_authenticity_tfidf(transcripts, stopwords):\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "    # Appliquer le modèle TF-IDF sur tous les transcripts\n",
    "    tfidf_matrix = vectorizer.fit_transform(transcripts)\n",
    "\n",
    "    # Calculer la moyenne des scores TF-IDF pour chaque transcript\n",
    "    tfidf_scores = np.mean(tfidf_matrix.toarray(), axis=1)\n",
    "\n",
    "    return tfidf_scores\n",
    "\n",
    "# Appliquer la fonction sur l'ensemble des transcripts\n",
    "df_score['authenticity_score'] = score_authenticity_tfidf(df_videos['transcript'].tolist(), french_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['nom', 'prénom', 'movement_score', 'speech_score', 'tone_score',\n",
       "       'intro_score', 'star_score', 'authenticity_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse et scoring du transcript avec GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "# Initialize OpenAI client\n",
    "\n",
    "load_dotenv()  # Charge les variables du fichier .env\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate the transcript (using the updated OpenAI setup)\n",
    "def evaluate_transcript_with_openai(transcript):\n",
    "    # Define the system message and user prompt\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Your task is to evaluate the following student transcript.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"\n",
    "        Voici une transcription de présentation d'un étudiant :\n",
    "\n",
    "        \"{transcript}\"\n",
    "\n",
    "        1. Évaluez la qualité de l'introduction en fonction des critères suivants :\n",
    "        - Présentation de l'entreprise ciblée et du poste visé,\n",
    "        - Choix d'une compétence psychosociale (soft skill) requise par le poste, et justification de l'importance de cette compétence,\n",
    "        - Formulation d'une question pertinente en lien avec cette compétence, en se mettant à la place du recruteur.\n",
    "        Donnez un score sur 3 :\n",
    "        - 1 pour la présentation de l'entreprise et du poste,\n",
    "        - 1 pour le choix et la justification de la compétence,\n",
    "        - 1 pour la question liée à la compétence.\n",
    "\n",
    "        2. Vérifiez si la méthode STAR (Situation, Tâche, Action, Résultat) est respectée dans la réponse. Donnez un score sur 4 :\n",
    "        - 1 pour la Situation (description du contexte),\n",
    "        - 1 pour la Tâche (explication des responsabilités et objectifs),\n",
    "        - 1 pour l'Action (détails des actions entreprises),\n",
    "        - 1 pour le Résultat (résultats obtenus et démonstration de la compétence).\n",
    "\n",
    "        3. Évaluez l'authenticité et la personnalisation de la réponse. Est-ce que l'étudiant donne des détails spécifiques montrant une réflexion personnelle ? Donnez un score sur 1 si la réponse semble authentique, 0 sinon.\n",
    "\n",
    "        Fournissez uniquement les scores dans ce format :\n",
    "        - introduction_score: X\n",
    "        - intro_company_score: Y\n",
    "        - intro_skill_score: Z\n",
    "        - intro_question_score: W\n",
    "        - star_situation_score: S\n",
    "        - star_task_score: T\n",
    "        - star_action_score: U\n",
    "        - star_result_score: V\n",
    "        - authenticity_score: A\n",
    "    \"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "    # Call the GPT model to get the evaluation\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Assuming you are using gpt-4o-mini\n",
    "        messages=messages,\n",
    "        max_tokens=300,  # Adjust based on the response length needed\n",
    "        temperature=0  # Ensure consistent and factual responses\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract the response content directly\n",
    "    response_text = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # Initialiser le dictionnaire des scores\n",
    "    scores = {\n",
    "        'introduction_score': 0,\n",
    "        'star_situation_score': 0,\n",
    "        'star_task_score': 0,\n",
    "        'star_action_score': 0,\n",
    "        'star_result_score': 0,\n",
    "        'authenticity_score': 0\n",
    "    }\n",
    "\n",
    "    # Extraire les scores de la réponse\n",
    "    for line in response_text.split('\\n'):\n",
    "        if 'introduction_score' in line:\n",
    "            scores['introduction_score'] = float(line.split(\":\")[1].strip())\n",
    "        elif 'star_situation_score' in line:\n",
    "            scores['star_situation_score'] = float(line.split(\":\")[1].strip())\n",
    "        elif 'star_task_score' in line:\n",
    "            scores['star_task_score'] = float(line.split(\":\")[1].strip())\n",
    "        elif 'star_action_score' in line:\n",
    "            scores['star_action_score'] = float(line.split(\":\")[1].strip())\n",
    "        elif 'star_result_score' in line:\n",
    "            scores['star_result_score'] = float(line.split(\":\")[1].strip())\n",
    "        elif 'authenticity_score' in line:\n",
    "            scores['authenticity_score'] = float(line.split(\":\")[1].strip())\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "# # Apply the function to each transcript and create a DataFrame with the results\n",
    "# df_scores_2 = pd.DataFrame(df_videos['transcript'].apply(evaluate_transcript_with_openai).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un DataFrame avec les noms\n",
    "df_score_gpt = df_score[['nom', 'prénom', 'movement_score', 'speech_score', 'tone_score']].copy()\n",
    "\n",
    "# Appliquer la fonction d'évaluation à chaque transcript et obtenir les résultats sous forme de dictionnaire\n",
    "df_scores_expanded = df_videos['transcript'].apply(evaluate_transcript_with_openai)\n",
    "\n",
    "# Convertir la liste de dictionnaires en colonnes distinctes\n",
    "df_scores_expanded = pd.json_normalize(df_scores_expanded)\n",
    "\n",
    "# Combiner les résultats avec les noms dans un nouveau DataFrame\n",
    "df_score_gpt = pd.concat([df_score_gpt, df_scores_expanded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>movement_score</th>\n",
       "      <th>speech_score</th>\n",
       "      <th>tone_score</th>\n",
       "      <th>introduction_score</th>\n",
       "      <th>star_situation_score</th>\n",
       "      <th>star_task_score</th>\n",
       "      <th>star_action_score</th>\n",
       "      <th>star_result_score</th>\n",
       "      <th>authenticity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>0.58554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.732170</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.379593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nom   prénom  movement_score  speech_score  tone_score  \\\n",
       "0   BETHOUX  camille         0.58554      0.000000    0.732170   \n",
       "1    MICHEL  Bernard         0.00000      0.379593    0.000000   \n",
       "2  BARTOZZI  Mathieu         1.00000      1.000000    0.625407   \n",
       "\n",
       "   introduction_score  star_situation_score  star_task_score  \\\n",
       "0                 2.0                   1.0              1.0   \n",
       "1                 2.0                   1.0              1.0   \n",
       "2                 1.0                   1.0              1.0   \n",
       "\n",
       "   star_action_score  star_result_score  authenticity_score  \n",
       "0                1.0                1.0                 0.0  \n",
       "1                1.0                0.0                 0.0  \n",
       "2                1.0                1.0                 1.0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_global_score=df_videos[['nom', 'prénom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_31798/3612915147.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_global_score['non_verbal_communication_score'] = (\n",
      "/var/folders/p9/_030_tzn0cx_x11mkmfz6w800000gn/T/ipykernel_31798/3612915147.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_global_score['non_verbal_communication_score'] = df_global_score['non_verbal_communication_score'].apply(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculer le score global de communication non verbale avec des pondérations\n",
    "df_global_score['non_verbal_communication_score'] = (\n",
    "    0.5 * df_score['movement_rate'] +\n",
    "    0.3 * df_score['speech_rate_score'] +\n",
    "    0.2 * df_score['tone_score']\n",
    ")\n",
    "\n",
    "# Calculer la moyenne des scores non verbaux\n",
    "threshold = df_global_score['non_verbal_communication_score'].mean()\n",
    "\n",
    "# Appliquer la moyenne comme seuil pour obtenir un score binaire (0 ou 1)\n",
    "df_global_score['non_verbal_communication_score'] = df_global_score['non_verbal_communication_score'].apply(\n",
    "    lambda score: 1 if score >= threshold else 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>prénom</th>\n",
       "      <th>non_verbal_communication_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BETHOUX</td>\n",
       "      <td>camille</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MICHEL</td>\n",
       "      <td>Bernard</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BARTOZZI</td>\n",
       "      <td>Mathieu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nom   prénom  non_verbal_communication_score\n",
       "0   BETHOUX  camille                               0\n",
       "1    MICHEL  Bernard                               0\n",
       "2  BARTOZZI  Mathieu                               1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_global_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video_auto_rating",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
